{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07aee07dc8f142aabdaccfbd64e9b93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db8ac9c16a8d40a48822baf5f5245559",
              "IPY_MODEL_25d5957f58a847959aa17633020be94c",
              "IPY_MODEL_e75815f4c5d04493a52bc85d53955481"
            ],
            "layout": "IPY_MODEL_d0fb377690ef429582d2f1d86f6a704e"
          }
        },
        "db8ac9c16a8d40a48822baf5f5245559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f7b85dcb2249259f7cdd3f2b06ee35",
            "placeholder": "​",
            "style": "IPY_MODEL_55be6558d8c74ba5bde0be5eb95814ae",
            "value": ""
          }
        },
        "25d5957f58a847959aa17633020be94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caccd69614834f33bcf4dbe038324c0c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_679b818384b64bc7a0ffd04141ab36a7",
            "value": 1
          }
        },
        "e75815f4c5d04493a52bc85d53955481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02547a2adc1c42bc85be811f75122ebe",
            "placeholder": "​",
            "style": "IPY_MODEL_363ccbf778734b1097c7574384a92c52",
            "value": " 24/? [00:00&lt;00:00, 35.53it/s]"
          }
        },
        "d0fb377690ef429582d2f1d86f6a704e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f7b85dcb2249259f7cdd3f2b06ee35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55be6558d8c74ba5bde0be5eb95814ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "caccd69614834f33bcf4dbe038324c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "679b818384b64bc7a0ffd04141ab36a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02547a2adc1c42bc85be811f75122ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363ccbf778734b1097c7574384a92c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3174956166114ee5b78ad5382f586ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf929735fbe94ec19e7db7b0164b5209",
              "IPY_MODEL_34194e294eda4ab19fe2c5b206751e4a",
              "IPY_MODEL_3c9299d2cd244844842f48f0a3e8ce16"
            ],
            "layout": "IPY_MODEL_7446472527a843beac4b764222f4836f"
          }
        },
        "bf929735fbe94ec19e7db7b0164b5209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f2a53b96dd74f5d92e9ce87c2e323fa",
            "placeholder": "​",
            "style": "IPY_MODEL_50f787e6f97144a39fc68a0d5510fb48",
            "value": "100%"
          }
        },
        "34194e294eda4ab19fe2c5b206751e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d515deb69814e718abb70ca4165e93c",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_998a60832811484b8373790da91ffda8",
            "value": 24
          }
        },
        "3c9299d2cd244844842f48f0a3e8ce16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45735d9ec97041f2b2578966c02a0522",
            "placeholder": "​",
            "style": "IPY_MODEL_0874737972a846a7ae6a7d199e55b49a",
            "value": " 24/24 [00:00&lt;00:00, 68.95it/s]"
          }
        },
        "7446472527a843beac4b764222f4836f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2a53b96dd74f5d92e9ce87c2e323fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f787e6f97144a39fc68a0d5510fb48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d515deb69814e718abb70ca4165e93c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998a60832811484b8373790da91ffda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45735d9ec97041f2b2578966c02a0522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0874737972a846a7ae6a7d199e55b49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c302e12935146708a5428dae1e38f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b30218eeee0452ab0bbce0135aaab37",
              "IPY_MODEL_3b31d8553bcf4b9ab6d2cfb32f916f05",
              "IPY_MODEL_6641c6b4273a45e38ee4d2cc4223f0d1"
            ],
            "layout": "IPY_MODEL_3ea140c89f734718954e3a39796242ac"
          }
        },
        "6b30218eeee0452ab0bbce0135aaab37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21e88e7dd734217a298297a2e29c2b3",
            "placeholder": "​",
            "style": "IPY_MODEL_b398e00586114d9087ff54e66b397171",
            "value": "100%"
          }
        },
        "3b31d8553bcf4b9ab6d2cfb32f916f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3118aa122bec434588efec7f39e4a595",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca1ecc7a977a4655aadbf5cf0dd5f230",
            "value": 24
          }
        },
        "6641c6b4273a45e38ee4d2cc4223f0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c002b931404f4537b1f210ebcfd09162",
            "placeholder": "​",
            "style": "IPY_MODEL_46de4719dd624496bbad9f64c03f971f",
            "value": " 24/24 [00:00&lt;00:00, 1979.15it/s]"
          }
        },
        "3ea140c89f734718954e3a39796242ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e21e88e7dd734217a298297a2e29c2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b398e00586114d9087ff54e66b397171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3118aa122bec434588efec7f39e4a595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1ecc7a977a4655aadbf5cf0dd5f230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c002b931404f4537b1f210ebcfd09162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46de4719dd624496bbad9f64c03f971f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76cfd52f2ef64185b1a91928a8532e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74b7336014fa41f0a81ce8e5a6583a18",
              "IPY_MODEL_42afa9fbfe63407db44ab7da053f2cef",
              "IPY_MODEL_21478281934b487485de26f7bdce492b"
            ],
            "layout": "IPY_MODEL_5be1ddca328b49c5943a60b42d192065"
          }
        },
        "74b7336014fa41f0a81ce8e5a6583a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fed373bf44ca460596bc7333d0f7e96e",
            "placeholder": "​",
            "style": "IPY_MODEL_b124bf57e1334c75b0acde94b3ebac86",
            "value": "100%"
          }
        },
        "42afa9fbfe63407db44ab7da053f2cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_598a4638e6054fa392d365b23025d4eb",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1ca465d9d8c42bfb037230374874aac",
            "value": 24
          }
        },
        "21478281934b487485de26f7bdce492b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3200ced680ab43aaa17daaf2039f51a4",
            "placeholder": "​",
            "style": "IPY_MODEL_65a5e05769e444218a55ef17bc84996c",
            "value": " 24/24 [00:00&lt;00:00, 1574.76it/s]"
          }
        },
        "5be1ddca328b49c5943a60b42d192065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fed373bf44ca460596bc7333d0f7e96e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b124bf57e1334c75b0acde94b3ebac86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "598a4638e6054fa392d365b23025d4eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ca465d9d8c42bfb037230374874aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3200ced680ab43aaa17daaf2039f51a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a5e05769e444218a55ef17bc84996c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90ea2519fab9472aba82a1bf2708d949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de5ac1bdb1d34a6ebad37e1383e6d6a0",
              "IPY_MODEL_dc9952e7a94d4837af2d23dc5c79ecea",
              "IPY_MODEL_6036ea1ed04340e682d93c8b24580b59"
            ],
            "layout": "IPY_MODEL_8d315cf07ea04c79b93a5b28d467f703"
          }
        },
        "de5ac1bdb1d34a6ebad37e1383e6d6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28ce0e709b424fd185cb564978d51176",
            "placeholder": "​",
            "style": "IPY_MODEL_c4182047ecca400c96a0c4497ca26558",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "dc9952e7a94d4837af2d23dc5c79ecea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b12574b09024095bd5fc4ad52d4d3f4",
            "max": 3071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d0b84d184074b58b2e3de520dbe99b0",
            "value": 3071
          }
        },
        "6036ea1ed04340e682d93c8b24580b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d7017f424de46e989206030c4e5f6e5",
            "placeholder": "​",
            "style": "IPY_MODEL_6e15ae4c6be244aaade621e474b9ff26",
            "value": " 3.07k/3.07k [00:00&lt;00:00, 88.3kB/s]"
          }
        },
        "8d315cf07ea04c79b93a5b28d467f703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ce0e709b424fd185cb564978d51176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4182047ecca400c96a0c4497ca26558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b12574b09024095bd5fc4ad52d4d3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0b84d184074b58b2e3de520dbe99b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d7017f424de46e989206030c4e5f6e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e15ae4c6be244aaade621e474b9ff26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e111c621b74d6bb1a9470cbcae58cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f963729c1ed4161aac5c003b80cc171",
              "IPY_MODEL_3ece70a3621c47ae93c4767047a6eb6d",
              "IPY_MODEL_c13ecb11eeb4471fb6e0c8ab89d13057"
            ],
            "layout": "IPY_MODEL_e3040d435ea3464db11b7242a82ec125"
          }
        },
        "2f963729c1ed4161aac5c003b80cc171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c47f633f59cc42a6a3d7604b5bc9af37",
            "placeholder": "​",
            "style": "IPY_MODEL_08ab8fca29954edda7fbbd59408def71",
            "value": "tokenizer.json: 100%"
          }
        },
        "3ece70a3621c47ae93c4767047a6eb6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_697193f87a1f43b88747202f3021fe81",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e54310fe0ec44e482ebbd9975f16bc7",
            "value": 7031660
          }
        },
        "c13ecb11eeb4471fb6e0c8ab89d13057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b4003f490c74428b41c7dc2ce8f8360",
            "placeholder": "​",
            "style": "IPY_MODEL_31a13a6890fa42069db7ce0bc3ed7080",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 16.1MB/s]"
          }
        },
        "e3040d435ea3464db11b7242a82ec125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c47f633f59cc42a6a3d7604b5bc9af37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ab8fca29954edda7fbbd59408def71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "697193f87a1f43b88747202f3021fe81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e54310fe0ec44e482ebbd9975f16bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b4003f490c74428b41c7dc2ce8f8360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31a13a6890fa42069db7ce0bc3ed7080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2112d05a6ca24ae8be5acd53bdfb82e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efddb922874f40119d95fedeb6fc36fc",
              "IPY_MODEL_9de0be9e5b9e48e898230914ab3464d8",
              "IPY_MODEL_6a42f7b2802347b2b248d7c154078c65"
            ],
            "layout": "IPY_MODEL_1268ddb5fe054614b8040ce3b7645e15"
          }
        },
        "efddb922874f40119d95fedeb6fc36fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee98b7d05fc40bc8847100e44c0fa0f",
            "placeholder": "​",
            "style": "IPY_MODEL_d263bd79b740499ea13669406196de5d",
            "value": "config.json: 100%"
          }
        },
        "9de0be9e5b9e48e898230914ab3464d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698fe9f9b91344178a0cb9f1bbfa2cf9",
            "max": 679,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8914c2b951b84c6d95032ec4403b5d8e",
            "value": 679
          }
        },
        "6a42f7b2802347b2b248d7c154078c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a523b3e24eb14ee799edfb060360ddfb",
            "placeholder": "​",
            "style": "IPY_MODEL_433482d7ee604f30bf01192c575064a0",
            "value": " 679/679 [00:00&lt;00:00, 42.6kB/s]"
          }
        },
        "1268ddb5fe054614b8040ce3b7645e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee98b7d05fc40bc8847100e44c0fa0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d263bd79b740499ea13669406196de5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "698fe9f9b91344178a0cb9f1bbfa2cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8914c2b951b84c6d95032ec4403b5d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a523b3e24eb14ee799edfb060360ddfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "433482d7ee604f30bf01192c575064a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42a6e57a7c3c4a6ba172aa69f43f9305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98d085d4e752405593db4e2170855d6f",
              "IPY_MODEL_d392085dba0d4f6f956f18326b5c461c",
              "IPY_MODEL_9e324965139046c89bde5c2f0e0aa3dc"
            ],
            "layout": "IPY_MODEL_db0f723e643c45538888635da46cd87d"
          }
        },
        "98d085d4e752405593db4e2170855d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda53b1d035f4bdcbb8d1e07dc7d18b1",
            "placeholder": "​",
            "style": "IPY_MODEL_3a6288ee843541589f82268de74320ac",
            "value": "model.safetensors: 100%"
          }
        },
        "d392085dba0d4f6f956f18326b5c461c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1570845c2b784b9291d21675bd7252d7",
            "max": 3554214621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc691bb52455405bb3c208831c55749e",
            "value": 3554214621
          }
        },
        "9e324965139046c89bde5c2f0e0aa3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_142a7521c86f4d328d20c51ff06b54c6",
            "placeholder": "​",
            "style": "IPY_MODEL_44fa1eaffbbe4609a60e21f7eccce195",
            "value": " 3.55G/3.55G [01:24&lt;00:00, 42.2MB/s]"
          }
        },
        "db0f723e643c45538888635da46cd87d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda53b1d035f4bdcbb8d1e07dc7d18b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6288ee843541589f82268de74320ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1570845c2b784b9291d21675bd7252d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc691bb52455405bb3c208831c55749e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "142a7521c86f4d328d20c51ff06b54c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44fa1eaffbbe4609a60e21f7eccce195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cd306c64b444933ad06ea391bd3f21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e209471b50b468c9ab7414b1a65714d",
              "IPY_MODEL_fe5ed9ad59ff49a981d0fb63484b77c0",
              "IPY_MODEL_f41070ea99434054984af571d0120031"
            ],
            "layout": "IPY_MODEL_97204fb76d3b4df9b56a1f87367d2e4f"
          }
        },
        "0e209471b50b468c9ab7414b1a65714d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be737d136b9941ac9331bd7902238abe",
            "placeholder": "​",
            "style": "IPY_MODEL_e4e7fb7fe7ab43a09960df1f9d930b44",
            "value": "generation_config.json: 100%"
          }
        },
        "fe5ed9ad59ff49a981d0fb63484b77c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da2b4c76beb46dea97ea4a8f5c93243",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82148c219f0e4a6bb5825ddc4b58123b",
            "value": 181
          }
        },
        "f41070ea99434054984af571d0120031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3c4fc964104fdb945ec579d11bd582",
            "placeholder": "​",
            "style": "IPY_MODEL_4c1bc08961ed4b8caaa10db4a18f0827",
            "value": " 181/181 [00:00&lt;00:00, 12.4kB/s]"
          }
        },
        "97204fb76d3b4df9b56a1f87367d2e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be737d136b9941ac9331bd7902238abe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e7fb7fe7ab43a09960df1f9d930b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da2b4c76beb46dea97ea4a8f5c93243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82148c219f0e4a6bb5825ddc4b58123b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f3c4fc964104fdb945ec579d11bd582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1bc08961ed4b8caaa10db4a18f0827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "130674f6c4e24e949c2e02bbf39bb31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e922753500ce45aeb721cd1df5749fd2",
              "IPY_MODEL_82b8fb662b924a0b852c26d0cf638957",
              "IPY_MODEL_8617e32136ca40769a8e1ee25f30d47b"
            ],
            "layout": "IPY_MODEL_205f4f1fd27c4b51ad79894070a2ba96"
          }
        },
        "e922753500ce45aeb721cd1df5749fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237b0e06249e490698f8db88d4f3bdf9",
            "placeholder": "​",
            "style": "IPY_MODEL_729787742a2e4def9e29595935f4a872",
            "value": "100%"
          }
        },
        "82b8fb662b924a0b852c26d0cf638957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e232526ba04432ae5d62cc9ccccb13",
            "max": 87,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_560394983ca84c149feb2d4a3db18de7",
            "value": 87
          }
        },
        "8617e32136ca40769a8e1ee25f30d47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6699e60d985941818971468b69e9a409",
            "placeholder": "​",
            "style": "IPY_MODEL_abcf423d549345d1bf80a8e9f3c9176a",
            "value": " 87/87 [00:05&lt;00:00, 20.19it/s]"
          }
        },
        "205f4f1fd27c4b51ad79894070a2ba96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "237b0e06249e490698f8db88d4f3bdf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729787742a2e4def9e29595935f4a872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28e232526ba04432ae5d62cc9ccccb13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560394983ca84c149feb2d4a3db18de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6699e60d985941818971468b69e9a409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abcf423d549345d1bf80a8e9f3c9176a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MdHINmkC-945",
        "outputId": "648a469e-4610-4b5f-f133-8dd48e9eb581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Running in Google Colab, installing requirements.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.3\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting trl\n",
            "  Downloading trl-0.15.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Collecting datasets>=2.21.0 (from trl)\n",
            "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.21.0->trl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (2.2.2)\n",
            "Collecting xxhash (from datasets>=2.21.0->trl)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.21.0->trl)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.11.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.17.0)\n",
            "Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.1-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets, bitsandbytes, trl\n",
            "Successfully installed bitsandbytes-0.45.2 datasets-3.3.1 dill-0.3.8 multiprocess-0.70.16 trl-0.15.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "    print(\"[INFO] Running in Google Colab, installing requirements.\")\n",
        "    !pip install torch torchvision torchaudio\n",
        "    !pip install PyMuPDF # for reading PDFs with Python\n",
        "    !pip install tqdm # for progress bars\n",
        "    !pip install accelerate peft bitsandbytes transformers trl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import fitz\n",
        "from tqdm.auto import tqdm\n",
        "from spacy.lang.en import English\n",
        "import re\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f'Device_Type: {device}')\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRYcDrkyAuIJ",
        "outputId": "e945e7b5-c63e-42b3-9249-396ee6bce1c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device_Type: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_download(pdf_path:str, url:str):\n",
        "# Download PDF if it doesn't already exist\n",
        "  if not os.path.exists(pdf_path):\n",
        "    print(\"File doesn't exist, downloading...\")\n",
        "    # The local filename to save the downloaded file\n",
        "    filename = pdf_path\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Open a file in binary write mode and save the content to it\n",
        "        with open(filename, \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"The file has been downloaded and saved as {filename}\")\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "  else:\n",
        "    print(f\"File {pdf_path} exists.\")"
      ],
      "metadata": {
        "id": "opBDTEacAn8x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"input.pdf\"\n",
        "url = \"https://openreview.net/pdf/d469d2a0fc79717910f7475e53c4e589161debe3.pdf\"\n",
        "\n",
        "pdf_download(pdf_path, url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB-nySAVBLLp",
        "outputId": "330c3d35-9389-41e9-a3e2-b3f66c9035d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File doesn't exist, downloading...\n",
            "The file has been downloaded and saved as input.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_formatter(text: str) -> str:\n",
        "    \"\"\"Performs minor formatting on text.\"\"\"\n",
        "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
        "    # Other potential text formatting functions can go here\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "hXve65-yCQ5x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
        "    doc = fitz.open(pdf_path)  # open a document\n",
        "    pages_and_texts = []\n",
        "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
        "        text = page.get_text()  # get plain text encoded as UTF-8\n",
        "        text = text_formatter(text)\n",
        "        pages_and_texts.append({\"page_number\": page_number - 0,\n",
        "                                \"page_char_count\": len(text),\n",
        "                                \"page_word_count\": len(text.split(\" \")),\n",
        "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
        "                                \"page_token_count\": len(text) / 4,  # 1 token\n",
        "                                \"text\": text})\n",
        "    return pages_and_texts"
      ],
      "metadata": {
        "id": "O2OIFNGoBvTA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
        "pages_and_texts[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "07aee07dc8f142aabdaccfbd64e9b93d",
            "db8ac9c16a8d40a48822baf5f5245559",
            "25d5957f58a847959aa17633020be94c",
            "e75815f4c5d04493a52bc85d53955481",
            "d0fb377690ef429582d2f1d86f6a704e",
            "a4f7b85dcb2249259f7cdd3f2b06ee35",
            "55be6558d8c74ba5bde0be5eb95814ae",
            "caccd69614834f33bcf4dbe038324c0c",
            "679b818384b64bc7a0ffd04141ab36a7",
            "02547a2adc1c42bc85be811f75122ebe",
            "363ccbf778734b1097c7574384a92c52"
          ]
        },
        "id": "bGf7Cb2uCHW5",
        "outputId": "fb928c34-6d42-410a-f7ad-efabe6f9ca8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07aee07dc8f142aabdaccfbd64e9b93d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': 0,\n",
              "  'page_char_count': 2666,\n",
              "  'page_word_count': 349,\n",
              "  'page_sentence_count_raw': 13,\n",
              "  'page_token_count': 666.5,\n",
              "  'text': 'RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning and Verification in Long-Horizon Generation Zihao Wang Peking University zhwang@stu.pku.edu.cn Anji Liu University of California, Los Angeles liuanji@cs.ucla.edu Haowei Lin Peking University linhaowei@pku.edu.cn Jiaqi Li Beijing Institute of General Artificial Intelligence lijiaqi@bigai.cn Xiaojian Ma Beijing Institute of General Artificial Intelligence xiaojian.ma@ucla.edu Yitao Liang∗ Peking University yitaol@pku.edu.cn Abstract We explore how iterative revising a chain of thoughts with the help of information retrieval significantly improves large language models’ reasoning and generation ability in long-horizon generation tasks, while hugely mitigating hallucination. In particular, the proposed method — retrieval-augmented thoughts (RAT) — revises each thought step one by one with retrieved information relevant to the task query, the current and the past thought steps, after the initial zero-shot CoT is generated. Applying RAT to GPT-3.5, GPT-4, and CodeLLaMA substantially improves their performances on various long-horizon generation tasks; on average of relatively increasing rating scores by 13.63% on code generation, 16.96% on mathematical reasoning, 19.2% on creative writing, and 42.78% on embodied task planning. 1 Introduction Large Language Models (LLMs) have achieved fruitful progress on various natural language rea- soning tasks [57, 59, 54, 67, 6], especially when combining large-scale models [49, 41] with sophisticated prompting strategies, notably chain-of-thought (CoT) prompting [57, 27]. However, there have been increasing concerns about the factual correctness of LLMs reasoning, citing the possible hallucinations in model responses [43] or the intermediate reasoning paths, i.e. CoTs [13]. This issue becomes more significant when it comes to zero-shot CoT prompting, aka. “let’s think step- by-step” [27] and long-horizon generation tasks that require multi-step and context-aware reasoning, including code generation, task planning, mathematical reasoning, etc. Factually valid intermediate thoughts could be critical to the successful completion of these tasks. Several prompting techniques have been proposed to mitigate this issue, one promising direction, Retrieval Augmented Generation (RAG) [30] seeks insights from human reasoning [22], and utilizes retrieved information to facilitate more factually grounded reasoning. In this paper, we explore how to synergize RAG with sophisticated long-horizon reasoning. Our intuition is that the hallucination ∗Corresponding Author. 38th Conference on Neural Information Processing Systems (NeurIPS 2024).'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_converter(pages_and_texts: list[dict]) -> list[dict]:\n",
        "  nlp = English()\n",
        "  nlp.add_pipe(\"sentencizer\")\n",
        "  for item in tqdm(pages_and_texts):\n",
        "      item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
        "      # Make sure all sentences are strings\n",
        "      item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
        "      # Count the sentences\n",
        "      item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])\n",
        "\n",
        "  return pages_and_texts"
      ],
      "metadata": {
        "id": "5JfjCqe6CXIo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages_and_texts_sen = sentence_converter(pages_and_texts)\n",
        "del pages_and_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3174956166114ee5b78ad5382f586ba4",
            "bf929735fbe94ec19e7db7b0164b5209",
            "34194e294eda4ab19fe2c5b206751e4a",
            "3c9299d2cd244844842f48f0a3e8ce16",
            "7446472527a843beac4b764222f4836f",
            "2f2a53b96dd74f5d92e9ce87c2e323fa",
            "50f787e6f97144a39fc68a0d5510fb48",
            "4d515deb69814e718abb70ca4165e93c",
            "998a60832811484b8373790da91ffda8",
            "45735d9ec97041f2b2578966c02a0522",
            "0874737972a846a7ae6a7d199e55b49a"
          ]
        },
        "id": "I3MZqcoRDkWJ",
        "outputId": "a2db8402-aa00-41f6-a67a-9c636dd35e53"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/24 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3174956166114ee5b78ad5382f586ba4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function that recursively splits a list into desired sizes\n",
        "def split_list(input_list: list,\n",
        "               slice_size: int) -> list[list[str]]:\n",
        "    \"\"\"\n",
        "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
        "\n",
        "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
        "    \"\"\"\n",
        "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]"
      ],
      "metadata": {
        "id": "dt0L92h5EHAZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunking(pages_and_texts_sen: list[dict]) -> list[dict]:\n",
        "# Define split size to turn groups of sentences into chunks\n",
        "  num_sentence_chunk_size = 10\n",
        "# Loop through pages and texts and split sentences into chunks\n",
        "  for item in tqdm(pages_and_texts_sen):\n",
        "      item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
        "                                          slice_size=num_sentence_chunk_size)\n",
        "      item[\"num_chunks\"] = len(item[\"sentence_chunks\"])\n",
        "\n",
        "  return pages_and_texts_sen"
      ],
      "metadata": {
        "id": "s86yjSrVDxCh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages_and_texts_sen_chunk = chunking(pages_and_texts_sen)\n",
        "del pages_and_texts_sen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5c302e12935146708a5428dae1e38f08",
            "6b30218eeee0452ab0bbce0135aaab37",
            "3b31d8553bcf4b9ab6d2cfb32f916f05",
            "6641c6b4273a45e38ee4d2cc4223f0d1",
            "3ea140c89f734718954e3a39796242ac",
            "e21e88e7dd734217a298297a2e29c2b3",
            "b398e00586114d9087ff54e66b397171",
            "3118aa122bec434588efec7f39e4a595",
            "ca1ecc7a977a4655aadbf5cf0dd5f230",
            "c002b931404f4537b1f210ebcfd09162",
            "46de4719dd624496bbad9f64c03f971f"
          ]
        },
        "id": "MHlS4bptETZg",
        "outputId": "5dbda506-3a2b-4855-988b-4cbc095c49ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/24 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c302e12935146708a5428dae1e38f08"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_chunks(pages_and_texts_sen_chunk: list[dict]) -> list():\n",
        "  # Split each chunk into its own item\n",
        "  pages_and_chunks = []\n",
        "  for item in tqdm(pages_and_texts_sen_chunk):\n",
        "      for sentence_chunk in item[\"sentence_chunks\"]:\n",
        "          chunk_dict = {}\n",
        "          chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
        "\n",
        "          # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
        "          joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
        "          joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo\n",
        "          chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
        "\n",
        "          # Get stats about the chunk\n",
        "          chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
        "          chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
        "          chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
        "\n",
        "          pages_and_chunks.append(chunk_dict)\n",
        "  return pages_and_chunks"
      ],
      "metadata": {
        "id": "jLgt0ZPFEgrA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pages_and_chunks = convert_chunks(pages_and_texts_sen_chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "76cfd52f2ef64185b1a91928a8532e46",
            "74b7336014fa41f0a81ce8e5a6583a18",
            "42afa9fbfe63407db44ab7da053f2cef",
            "21478281934b487485de26f7bdce492b",
            "5be1ddca328b49c5943a60b42d192065",
            "fed373bf44ca460596bc7333d0f7e96e",
            "b124bf57e1334c75b0acde94b3ebac86",
            "598a4638e6054fa392d365b23025d4eb",
            "b1ca465d9d8c42bfb037230374874aac",
            "3200ced680ab43aaa17daaf2039f51a4",
            "65a5e05769e444218a55ef17bc84996c"
          ]
        },
        "id": "sGh12KK7FQNh",
        "outputId": "80f4070a-d358-4545-9505-62499e90f2b3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/24 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76cfd52f2ef64185b1a91928a8532e46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.9 ms, sys: 964 µs, total: 16.8 ms\n",
            "Wall time: 17.1 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
      ],
      "metadata": {
        "id": "6dnrDsd8gXpd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path,torch_dtype=torch.float16).to(device)"
      ],
      "metadata": {
        "id": "aXZ81fgufgVl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "90ea2519fab9472aba82a1bf2708d949",
            "de5ac1bdb1d34a6ebad37e1383e6d6a0",
            "dc9952e7a94d4837af2d23dc5c79ecea",
            "6036ea1ed04340e682d93c8b24580b59",
            "8d315cf07ea04c79b93a5b28d467f703",
            "28ce0e709b424fd185cb564978d51176",
            "c4182047ecca400c96a0c4497ca26558",
            "5b12574b09024095bd5fc4ad52d4d3f4",
            "0d0b84d184074b58b2e3de520dbe99b0",
            "5d7017f424de46e989206030c4e5f6e5",
            "6e15ae4c6be244aaade621e474b9ff26",
            "83e111c621b74d6bb1a9470cbcae58cc",
            "2f963729c1ed4161aac5c003b80cc171",
            "3ece70a3621c47ae93c4767047a6eb6d",
            "c13ecb11eeb4471fb6e0c8ab89d13057",
            "e3040d435ea3464db11b7242a82ec125",
            "c47f633f59cc42a6a3d7604b5bc9af37",
            "08ab8fca29954edda7fbbd59408def71",
            "697193f87a1f43b88747202f3021fe81",
            "8e54310fe0ec44e482ebbd9975f16bc7",
            "7b4003f490c74428b41c7dc2ce8f8360",
            "31a13a6890fa42069db7ce0bc3ed7080",
            "2112d05a6ca24ae8be5acd53bdfb82e1",
            "efddb922874f40119d95fedeb6fc36fc",
            "9de0be9e5b9e48e898230914ab3464d8",
            "6a42f7b2802347b2b248d7c154078c65",
            "1268ddb5fe054614b8040ce3b7645e15",
            "2ee98b7d05fc40bc8847100e44c0fa0f",
            "d263bd79b740499ea13669406196de5d",
            "698fe9f9b91344178a0cb9f1bbfa2cf9",
            "8914c2b951b84c6d95032ec4403b5d8e",
            "a523b3e24eb14ee799edfb060360ddfb",
            "433482d7ee604f30bf01192c575064a0",
            "42a6e57a7c3c4a6ba172aa69f43f9305",
            "98d085d4e752405593db4e2170855d6f",
            "d392085dba0d4f6f956f18326b5c461c",
            "9e324965139046c89bde5c2f0e0aa3dc",
            "db0f723e643c45538888635da46cd87d",
            "fda53b1d035f4bdcbb8d1e07dc7d18b1",
            "3a6288ee843541589f82268de74320ac",
            "1570845c2b784b9291d21675bd7252d7",
            "dc691bb52455405bb3c208831c55749e",
            "142a7521c86f4d328d20c51ff06b54c6",
            "44fa1eaffbbe4609a60e21f7eccce195",
            "6cd306c64b444933ad06ea391bd3f21a",
            "0e209471b50b468c9ab7414b1a65714d",
            "fe5ed9ad59ff49a981d0fb63484b77c0",
            "f41070ea99434054984af571d0120031",
            "97204fb76d3b4df9b56a1f87367d2e4f",
            "be737d136b9941ac9331bd7902238abe",
            "e4e7fb7fe7ab43a09960df1f9d930b44",
            "4da2b4c76beb46dea97ea4a8f5c93243",
            "82148c219f0e4a6bb5825ddc4b58123b",
            "2f3c4fc964104fdb945ec579d11bd582",
            "4c1bc08961ed4b8caaa10db4a18f0827"
          ]
        },
        "outputId": "24250e92-a22c-477f-ee7a-d490ff574e45"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90ea2519fab9472aba82a1bf2708d949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83e111c621b74d6bb1a9470cbcae58cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2112d05a6ca24ae8be5acd53bdfb82e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42a6e57a7c3c4a6ba172aa69f43f9305"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cd306c64b444933ad06ea391bd3f21a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Quantization"
      ],
      "metadata": {
        "id": "zKZaQs3BrUlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BitsAndBytesConfig\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_path,\n",
        "#     quantization_config=bnb_config,\n",
        "#     device_map=device\n",
        "# )"
      ],
      "metadata": {
        "id": "Nst3-bE4pKty"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embedding(text:str):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\",padding=True ,truncation=True).to(device)\n",
        "\n",
        "  # Forward pass through the model to get hidden states\n",
        "  with torch.no_grad():\n",
        "      outputs = model(**inputs, output_hidden_states=True)\n",
        "\n",
        "  # Extract the hidden states\n",
        "  hidden_states = outputs.hidden_states  # This is a tuple with the hidden states from all layers\n",
        "\n",
        "  # Typically, the last hidden state is used as the embedding\n",
        "  # hidden_states[-1] has the shape [batch_size, sequence_length, hidden_size]\n",
        "  embedding = hidden_states[-1][:, 0, :]\n",
        "\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "kvAvjXgqfkOG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding Generation (Sequential Processing)\n"
      ],
      "metadata": {
        "id": "No-Felr8r6fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings(pages_and_chunks: list):\n",
        "  # Create embeddings one by one on the GPU\n",
        "  for item in tqdm(pages_and_chunks):\n",
        "      item[\"embedding\"] = generate_embedding(item[\"sentence_chunk\"])\n",
        "  return pages_and_chunks"
      ],
      "metadata": {
        "id": "-1qZsIzHOl3b"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pages_and_chunks = create_embeddings(pages_and_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "130674f6c4e24e949c2e02bbf39bb31f",
            "e922753500ce45aeb721cd1df5749fd2",
            "82b8fb662b924a0b852c26d0cf638957",
            "8617e32136ca40769a8e1ee25f30d47b",
            "205f4f1fd27c4b51ad79894070a2ba96",
            "237b0e06249e490698f8db88d4f3bdf9",
            "729787742a2e4def9e29595935f4a872",
            "28e232526ba04432ae5d62cc9ccccb13",
            "560394983ca84c149feb2d4a3db18de7",
            "6699e60d985941818971468b69e9a409",
            "abcf423d549345d1bf80a8e9f3c9176a"
          ]
        },
        "id": "nHOoVMo6MDWS",
        "outputId": "a37b601d-ec6e-4287-8f84-12cc1830ad5a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/87 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "130674f6c4e24e949c2e02bbf39bb31f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.86 s, sys: 57.7 ms, total: 4.91 s\n",
            "Wall time: 5.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages_and_chunks[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwF81bxM5_6d",
        "outputId": "4411f8b8-31d6-4a9c-cf34-3f9c109ae6ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': 0,\n",
              "  'sentence_chunk': 'RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning and Verification in Long-Horizon Generation Zihao Wang Peking University zhwang@stu.pku.edu.cn Anji Liu University of California, Los Angeles liuanji@cs.ucla.edu Haowei Lin Peking University linhaowei@pku.edu.cn Jiaqi Li Beijing Institute of General Artificial Intelligence lijiaqi@bigai.cn Xiaojian Ma Beijing Institute of General Artificial Intelligence xiaojian.ma@ucla.edu Yitao Liang∗ Peking University yitaol@pku.edu.cn Abstract We explore how iterative revising a chain of thoughts with the help of information retrieval significantly improves large language models’ reasoning and generation ability in long-horizon generation tasks, while hugely mitigating hallucination. In particular, the proposed method — retrieval-augmented thoughts (RAT) — revises each thought step one by one with retrieved information relevant to the task query, the current and the past thought steps, after the initial zero-shot CoT is generated. Applying RAT to GPT-3.5, GPT-4, and CodeLLaMA substantially improves their performances on various long-horizon generation tasks; on average of relatively increasing rating scores by 13.63% on code generation, 16.96% on mathematical reasoning, 19.2% on creative writing, and 42.78% on embodied task planning.1 Introduction Large Language Models (LLMs) have achieved fruitful progress on various natural language rea- soning tasks [57, 59, 54, 67, 6], especially when combining large-scale models [49, 41] with sophisticated prompting strategies, notably chain-of-thought (CoT) prompting [57, 27]. However, there have been increasing concerns about the factual correctness of LLMs reasoning, citing the possible hallucinations in model responses [43] or the intermediate reasoning paths, i.e. CoTs [13]. This issue becomes more significant when it comes to zero-shot CoT prompting, aka. “let’s think step- by-step” [27] and long-horizon generation tasks that require multi-step and context-aware reasoning, including code generation, task planning, mathematical reasoning, etc. Factually valid intermediate thoughts could be critical to the successful completion of these tasks. Several prompting techniques have been proposed to mitigate this issue, one promising direction, Retrieval Augmented Generation (RAG) [30] seeks insights from human reasoning [22], and utilizes retrieved information to facilitate more factually grounded reasoning. In this paper, we explore how to synergize RAG with sophisticated long-horizon reasoning.',\n",
              "  'chunk_char_count': 2529,\n",
              "  'chunk_word_count': 331,\n",
              "  'chunk_token_count': 632.25,\n",
              "  'embedding': tensor([[ 1.8252, -2.6387,  1.8164,  ...,  0.1477,  2.3477,  0.9448]],\n",
              "         device='cuda:0', dtype=torch.float16)},\n",
              " {'page_number': 0,\n",
              "  'sentence_chunk': 'Our intuition is that the hallucination ∗Corresponding Author.38th Conference on Neural Information Processing Systems (NeurIPS 2024).',\n",
              "  'chunk_char_count': 134,\n",
              "  'chunk_word_count': 16,\n",
              "  'chunk_token_count': 33.5,\n",
              "  'embedding': tensor([[ 1.8232, -2.6387,  1.8164,  ...,  0.1461,  2.3516,  0.9448]],\n",
              "         device='cuda:0', dtype=torch.float16)}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding Generation (Batch Processing)"
      ],
      "metadata": {
        "id": "CBGZfAHdrmZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks]\n",
        "# text_chunk_embeddings = generate_embedding(text_chunks)"
      ],
      "metadata": {
        "id": "ynq_bg_1NhHy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "sH-InXYkhbOl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = list()\n",
        "for i in pages_and_chunks:\n",
        "  embeddings.append(i['embedding'])\n",
        "embeddings = torch.cat(embeddings, dim=0)"
      ],
      "metadata": {
        "id": "Z6iPrEcF5Thr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util\n",
        "query = \"RAT\"\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# 2. Embed the query to the same numerical space as the text examples\n",
        "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
        "query_embedding = generate_embedding(query)\n",
        "\n",
        "# 3. Get similarity scores with the dot product\n",
        "from time import perf_counter as timer\n",
        "\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "# 4. Get the top-k results (we'll keep this to 5)\n",
        "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
        "top_results_dot_product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91wyUO4IsoUx",
        "outputId": "0e2313c5-871c-4dae-f11f-283e724f5c34"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: RAT\n",
            "Time take to get scores on 87 embeddings: 0.03435 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([8552., 8552., 8552., 8552., 8552.], device='cuda:0',\n",
              "       dtype=torch.float16),\n",
              "indices=tensor([1, 0, 2, 4, 3], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define helper function to print wrapped text\n",
        "import textwrap\n",
        "\n",
        "def print_wrapped(text, wrap_length=80):\n",
        "    wrapped_text = textwrap.fill(text, wrap_length)\n",
        "    print(wrapped_text)"
      ],
      "metadata": {
        "id": "Q6LaHZkR3n6p"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query: '{query}'\\n\")\n",
        "print(\"Results:\")\n",
        "# Loop through zipped together scores and indicies from torch.topk\n",
        "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "    print(\"Text:\")\n",
        "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
        "    # Print the page number too so we can reference the textbook further (and check the results)\n",
        "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho-dQJvM7UH4",
        "outputId": "64c8cad6-505e-43b7-cd9d-ecece7273f98"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'RAT'\n",
            "\n",
            "Results:\n",
            "Score: 8552.0000\n",
            "Text:\n",
            "Our intuition is that the hallucination ∗Corresponding Author.38th Conference on\n",
            "Neural Information Processing Systems (NeurIPS 2024).\n",
            "Page number: 0\n",
            "\n",
            "\n",
            "Score: 8552.0000\n",
            "Text:\n",
            "RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning and\n",
            "Verification in Long-Horizon Generation Zihao Wang Peking University\n",
            "zhwang@stu.pku.edu.cn Anji Liu University of California, Los Angeles\n",
            "liuanji@cs.ucla.edu Haowei Lin Peking University linhaowei@pku.edu.cn Jiaqi Li\n",
            "Beijing Institute of General Artificial Intelligence lijiaqi@bigai.cn Xiaojian\n",
            "Ma Beijing Institute of General Artificial Intelligence xiaojian.ma@ucla.edu\n",
            "Yitao Liang∗ Peking University yitaol@pku.edu.cn Abstract We explore how\n",
            "iterative revising a chain of thoughts with the help of information retrieval\n",
            "significantly improves large language models’ reasoning and generation ability\n",
            "in long-horizon generation tasks, while hugely mitigating hallucination. In\n",
            "particular, the proposed method — retrieval-augmented thoughts (RAT) — revises\n",
            "each thought step one by one with retrieved information relevant to the task\n",
            "query, the current and the past thought steps, after the initial zero-shot CoT\n",
            "is generated. Applying RAT to GPT-3.5, GPT-4, and CodeLLaMA substantially\n",
            "improves their performances on various long-horizon generation tasks; on average\n",
            "of relatively increasing rating scores by 13.63% on code generation, 16.96% on\n",
            "mathematical reasoning, 19.2% on creative writing, and 42.78% on embodied task\n",
            "planning.1 Introduction Large Language Models (LLMs) have achieved fruitful\n",
            "progress on various natural language rea- soning tasks [57, 59, 54, 67, 6],\n",
            "especially when combining large-scale models [49, 41] with sophisticated\n",
            "prompting strategies, notably chain-of-thought (CoT) prompting [57, 27].\n",
            "However, there have been increasing concerns about the factual correctness of\n",
            "LLMs reasoning, citing the possible hallucinations in model responses [43] or\n",
            "the intermediate reasoning paths, i.e. CoTs [13]. This issue becomes more\n",
            "significant when it comes to zero-shot CoT prompting, aka. “let’s think step-\n",
            "by-step” [27] and long-horizon generation tasks that require multi-step and\n",
            "context-aware reasoning, including code generation, task planning, mathematical\n",
            "reasoning, etc. Factually valid intermediate thoughts could be critical to the\n",
            "successful completion of these tasks. Several prompting techniques have been\n",
            "proposed to mitigate this issue, one promising direction, Retrieval Augmented\n",
            "Generation (RAG) [30] seeks insights from human reasoning [22], and utilizes\n",
            "retrieved information to facilitate more factually grounded reasoning. In this\n",
            "paper, we explore how to synergize RAG with sophisticated long-horizon\n",
            "reasoning.\n",
            "Page number: 0\n",
            "\n",
            "\n",
            "Score: 8552.0000\n",
            "Text:\n",
            "Step 0 Draft initial step-by-step zero-shot CoTs based on the task prompt. A\n",
            "task prompt is given by a human user. LLM makes zero-shot step-by-step reasoning\n",
            "based on the prompt. This initial zero-shot CoT answer may be ﬂawed. How to\n",
            "obtain diamond sword in Minecraft?LLM Task Prompt (I) T1: Mine 4 planks (ﬂawed)\n",
            "T2: craft table from planks ... Tn: Craft diamond sword Initial CoTs Retrieve\n",
            "with the task prompt and previous generated CoTs. LLM revises the i-th steps in\n",
            "thought chains (T1:i-1, Ti) based on the retrieved content. The thought chain\n",
            "(T1:i-1, Ti) is replaced with the revised generation T1:i. T1* T2 T3 Tn ... T1*:\n",
            "Mine 4 logs T2: craft table from planks ... Tn: Craft diamond sword Revised CoTs\n",
            "Step 1 - Step n Step 1 Step n Retrieve relevant information and iteratively\n",
            "revise each CoT with all previous generations in context. Retrieval T1 Library\n",
            "R1 Augmented Revision I Rn T1* T1* T2* T3* Tn* ... T1*: Mine 4 logs T2*: craft\n",
            "12 planks ... Tn*: Craft diamond sword Revised CoTs Retrieval Library Rn T1* T2*\n",
            "Tn ... ... Augmented Revision I Rn T1* T2* ... T1 T2 T3 Tn ... * * * Figure 1:\n",
            "Pipeline of Retrieval Augmented Thoughts (RAT). Given a task prompt (denoted as\n",
            "I in the figure), RAT starts from initial step-by-step thoughts (T1, T2, · · · ,\n",
            "Tn) produced by an LLM in zero-shot (“let’s think step by step”).\n",
            "Page number: 1\n",
            "\n",
            "\n",
            "Score: 8552.0000\n",
            "Text:\n",
            "We employ several LLMs of varied scales: GPT-3.5 [6], GPT-4 [41], CodeLLaMA-7b\n",
            "[46]. The results indicate that combing RAT with these LLMs elicits strong\n",
            "advantages over vanilla CoT prompting and RAG approaches. In particular, we\n",
            "observe new state-of-the-art level of performances across our selection of\n",
            "tasks: 1) code generation: HumanEval (+20.94%), HumanEval+ (+18.89%), MBPP\n",
            "(+14.83%), MBPP+ (+1.86%); 2) mathematical reasoning problems: GSM8K (+8.36%),\n",
            "and GSMHard (+31.37%); 3) Minecraft task planning (2.96 times on executability\n",
            "and +51.94% on plausibility); 4) creative writing (+19.19% on human score). Our\n",
            "additional ablation studies further confirm the crucial roles played by the two\n",
            "key ingredients of RAT: revising CoT using RAG and progressive revision &\n",
            "generation. This work reveals how can LLMs revise their reasoning process in a\n",
            "zero-shot fashion with the help of outside knowledge, just as what humans do.2\n",
            "Related Works Retrieval-augmented Generation (RAG). Recently, RAG has gained\n",
            "popularity for boosting the performance of LLMs by guiding their generation\n",
            "process using the retrieved knowledge [65]. Without updating model parameters\n",
            "that may be expensive [29] or unstable [26, 25], RAG is a 2\n",
            "Page number: 1\n",
            "\n",
            "\n",
            "Score: 8552.0000\n",
            "Text:\n",
            "Some thought steps (such as T1 in the figure) may be flawed due to\n",
            "hallucination. RAT iteratively revises each thought step (T ⋆ 1 , T ⋆ 2 , · · ·\n",
            ", T ⋆ i−1, Ti) using RAG from an external knowledge base (denoted as Library).\n",
            "Detailed prompting strategy can be found in Section 3.2.within the intermediate\n",
            "reasoning process could be alleviated through the help of outside knowledge. The\n",
            "resulting prompting strategy, retrieval-augmented thoughts (RAT), is illustrated\n",
            "in Figure 1. Our strategy comprises two key ideas. Firstly, the initial zero-\n",
            "shot CoT produced by LLMs along with the original task prompt will be used as\n",
            "queries to retrieve the information that could help revise the possibly flawed\n",
            "CoT. Secondly, instead of retrieving and revising with the full CoT and\n",
            "producing the final response at once, we devise a progressive approach, where\n",
            "LLMs produce the response step-by-step following the CoT (a series of subtasks),\n",
            "and only the current thought step will be revised based on the information\n",
            "retrieved with task prompt, the current and the past CoTs. This strategy can be\n",
            "an analogy to the human reasoning process: we utilize outside knowledge to\n",
            "adjust our step-by-step thinking during complex long-horizon problem-solving\n",
            "[22]. A comparison of RAT and counterparts can be found in Figure 2. We evaluate\n",
            "RAT on a wide collection of challenging long-horizon tasks, including code\n",
            "generation, mathematical reasoning, embodied task planning, and creative\n",
            "writing.\n",
            "Page number: 1\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the query\n",
        "query = \"Our goal is to support long-horizon reasoning and generation while mitigating hallucination when using LLMs.\"\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# 2. Embed the query to the same numerical space as the text examples\n",
        "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
        "query_embedding = generate_embedding(query)\n",
        "\n",
        "# 3. Get similarity scores with the cosine similarity\n",
        "from time import perf_counter as timer\n",
        "\n",
        "start_time = timer()\n",
        "cosine_similarity = util.cos_sim(a=query_embedding, b=embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "# 4. Get the top-k results (we'll keep this to 5)\n",
        "top_results_cos_sim = torch.topk(cosine_similarity, k=5)\n",
        "top_results_cos_sim"
      ],
      "metadata": {
        "id": "ipsCDist7XlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b2bf58-3ece-45f5-9b33-8fadb44c5af5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Our goal is to support long-horizon reasoning and generation while mitigating hallucination when using LLMs.\n",
            "Time take to get scores on 87 embeddings: 0.07345 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([1., 1., 1., 1., 1.], device='cuda:0', dtype=torch.float16),\n",
              "indices=tensor([2, 1, 3, 6, 5], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query: '{query}'\\n\")\n",
        "print(\"Results:\")\n",
        "# Loop through zipped together scores and indicies from torch.topk\n",
        "for score, idx in zip(top_results_cos_sim[0], top_results_cos_sim[1]):\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "    print(\"Text:\")\n",
        "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
        "    # Print the page number too so we can reference the textbook further (and check the results)\n",
        "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "ukT-iTVM1A4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b1f1eb-a52b-4f03-e62b-281337b3d4aa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'Our goal is to support long-horizon reasoning and generation while mitigating hallucination when using LLMs.'\n",
            "\n",
            "Results:\n",
            "Score: 1.0000\n",
            "Text:\n",
            "Step 0 Draft initial step-by-step zero-shot CoTs based on the task prompt. A\n",
            "task prompt is given by a human user. LLM makes zero-shot step-by-step reasoning\n",
            "based on the prompt. This initial zero-shot CoT answer may be ﬂawed. How to\n",
            "obtain diamond sword in Minecraft?LLM Task Prompt (I) T1: Mine 4 planks (ﬂawed)\n",
            "T2: craft table from planks ... Tn: Craft diamond sword Initial CoTs Retrieve\n",
            "with the task prompt and previous generated CoTs. LLM revises the i-th steps in\n",
            "thought chains (T1:i-1, Ti) based on the retrieved content. The thought chain\n",
            "(T1:i-1, Ti) is replaced with the revised generation T1:i. T1* T2 T3 Tn ... T1*:\n",
            "Mine 4 logs T2: craft table from planks ... Tn: Craft diamond sword Revised CoTs\n",
            "Step 1 - Step n Step 1 Step n Retrieve relevant information and iteratively\n",
            "revise each CoT with all previous generations in context. Retrieval T1 Library\n",
            "R1 Augmented Revision I Rn T1* T1* T2* T3* Tn* ... T1*: Mine 4 logs T2*: craft\n",
            "12 planks ... Tn*: Craft diamond sword Revised CoTs Retrieval Library Rn T1* T2*\n",
            "Tn ... ... Augmented Revision I Rn T1* T2* ... T1 T2 T3 Tn ... * * * Figure 1:\n",
            "Pipeline of Retrieval Augmented Thoughts (RAT). Given a task prompt (denoted as\n",
            "I in the figure), RAT starts from initial step-by-step thoughts (T1, T2, · · · ,\n",
            "Tn) produced by an LLM in zero-shot (“let’s think step by step”).\n",
            "Page number: 1\n",
            "\n",
            "\n",
            "Score: 1.0000\n",
            "Text:\n",
            "Our intuition is that the hallucination ∗Corresponding Author.38th Conference on\n",
            "Neural Information Processing Systems (NeurIPS 2024).\n",
            "Page number: 0\n",
            "\n",
            "\n",
            "Score: 1.0000\n",
            "Text:\n",
            "Some thought steps (such as T1 in the figure) may be flawed due to\n",
            "hallucination. RAT iteratively revises each thought step (T ⋆ 1 , T ⋆ 2 , · · ·\n",
            ", T ⋆ i−1, Ti) using RAG from an external knowledge base (denoted as Library).\n",
            "Detailed prompting strategy can be found in Section 3.2.within the intermediate\n",
            "reasoning process could be alleviated through the help of outside knowledge. The\n",
            "resulting prompting strategy, retrieval-augmented thoughts (RAT), is illustrated\n",
            "in Figure 1. Our strategy comprises two key ideas. Firstly, the initial zero-\n",
            "shot CoT produced by LLMs along with the original task prompt will be used as\n",
            "queries to retrieve the information that could help revise the possibly flawed\n",
            "CoT. Secondly, instead of retrieving and revising with the full CoT and\n",
            "producing the final response at once, we devise a progressive approach, where\n",
            "LLMs produce the response step-by-step following the CoT (a series of subtasks),\n",
            "and only the current thought step will be revised based on the information\n",
            "retrieved with task prompt, the current and the past CoTs. This strategy can be\n",
            "an analogy to the human reasoning process: we utilize outside knowledge to\n",
            "adjust our step-by-step thinking during complex long-horizon problem-solving\n",
            "[22]. A comparison of RAT and counterparts can be found in Figure 2. We evaluate\n",
            "RAT on a wide collection of challenging long-horizon tasks, including code\n",
            "generation, mathematical reasoning, embodied task planning, and creative\n",
            "writing.\n",
            "Page number: 1\n",
            "\n",
            "\n",
            "Score: 1.0000\n",
            "Text:\n",
            "Methods without RAG often generate incorrect information with hallucination,\n",
            "classical RAG is highly related to retrieved content with a loose structure, and\n",
            "RAT-generated texts perform best in terms of accuracy and completeness. Bottom:\n",
            "The quantitative performance comparison for different LLM methods on embodied\n",
            "planning, mathematical reasoning, code generation, and creative writing tasks.\n",
            "RAT outperforms all the baselines on all tasks.cost-effective way for LLMs to\n",
            "interact with the external world [18, 29]. RAG is widely applied to downstream\n",
            "tasks, such as code generation [68, 38, 39], question answering [3, 48], and\n",
            "creative writing [58, 1]. Reasoning-enhanced RAG. Some recent works also\n",
            "leverage reasoning to enhance the perfor- mance of RAG [32]. For example, IRCoT\n",
            "[51] exploits CoT to generate better queries for retrieval, IRGR [45] performs\n",
            "iteratively retrieval to search for suitable premises for multi-hop QA, GEEK\n",
            "[36] can choose to query external knowledge or perform a single logical\n",
            "reasoning step in long-horizon generation tasks, and ITRG [14] performs\n",
            "retrieval based on the last-step generation. Active RAG [24] also utilizes\n",
            "reasoning to enhance the quality of language model retrieval for better\n",
            "completion of QA tasks. These previous RAG methods simply adopt a single query\n",
            "to retrieve the knowledge for question-answering tasks [17, 15, 24].\n",
            "Page number: 2\n",
            "\n",
            "\n",
            "Score: 1.0000\n",
            "Text:\n",
            "DIRECT Q: Introduce Jin Yong's life. A: Jin Yong, born Louis Cha in 1924 …\n",
            "Graduating from the University of Cambridge, he later begin to write full-time,\n",
            "leaving an indelible mark on Chinese literature and culture... [not informative,\n",
            "loose structure] 😿 CoT Q: Introduce Jin Yong's life. Let’s think it step-by-\n",
            "step. A: Jin Yong is a Chinese novelist... The details of his life are\n",
            "introduced as follows: Early Life: Jin Yong, born on February 6, 1924...\n",
            "Education: ... He graduated from the University of Cambridge before dedicating\n",
            "himself to writing full-time... Literature: His ﬁrst novel, \"The Book and the\n",
            "Sword,\" was published in 1955, followed by successful works including \"Handsome\n",
            "Siblings\", ... RAT Q: Introduce Jin Yong's life. Let’s think it step-by-step. A:\n",
            "Jin Yong is a Chinese novelist... The details of his life are introduced as\n",
            "follows: Early Life: Jin Yong, born on February 6, 1924, in Haining, Zhejiang\n",
            "province, China, was a renowned Chinese novelist known by his pen name Louis\n",
            "Cha.... Education: ... In his eighties, he applied at Cambridge University for a\n",
            "doctorate in AsianStudies and another doctorate in Chinese literature at Peking\n",
            "University... Literature: In 1955, Jin Yong published his first arts novel, \"The\n",
            "Book and the Sword,\" which achieved immense success and marked the beginning of\n",
            "his literary journey. He went on to write many acclaimed novels, including the\n",
            "revered \"Legends of the Condor Heroes\" and \"The Deer and the Cauldron.\"😸 RAG Q:\n",
            "Introduce Jin Yong's life. A: Jin Yong, born Louis Cha in 1924... In his\n",
            "eighties, he applied at Cambridge University for a doctorate in Asian Studies\n",
            "and another doctorate in Chinese literature at Peking University... [too\n",
            "specific, loose structure]😾 😿 Figure 2: Top: An example of different LLM\n",
            "reasoning methods on creative generation tasks. Red text indicates errors or\n",
            "illusions in the text generated by LLM, while green text represents correct\n",
            "generation.\n",
            "Page number: 2\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_resources(query: str,\n",
        "                                embeddings: torch.tensor,\n",
        "                                n_resources_to_return: int=5,\n",
        "                                print_time: bool=True):\n",
        "    \"\"\"\n",
        "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Embed the query\n",
        "    query_embedding = generate_embedding(query)\n",
        "\n",
        "    # Get dot product scores on embeddings\n",
        "    start_time = timer()\n",
        "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
        "    end_time = timer()\n",
        "\n",
        "    if print_time:\n",
        "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "    scores, indices = torch.topk(input=dot_scores,\n",
        "                                 k=n_resources_to_return)\n",
        "\n",
        "    return scores, indices\n",
        "\n",
        "def print_top_results_and_scores(query: str,\n",
        "                                 embeddings: torch.tensor,\n",
        "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
        "                                 n_resources_to_return: int=5):\n",
        "    \"\"\"\n",
        "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
        "\n",
        "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
        "    \"\"\"\n",
        "\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings,\n",
        "                                                  n_resources_to_return=n_resources_to_return)\n",
        "\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    print(\"Results:\")\n",
        "    # Loop through zipped together scores and indicies\n",
        "    for score, index in zip(scores, indices):\n",
        "        print(f\"Score: {score:.4f}\")\n",
        "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
        "        # Print the page number too so we can reference the textbook further and check the results\n",
        "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "88I0a4eQ9lzc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is RAT?\"\n",
        "\n",
        "# Get just the scores and indices of top related results\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4D91g4cy0we",
        "outputId": "750ecbe7-6595-4b0d-ef22-fcfb934f5e8b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Time taken to get scores on 87 embeddings: 0.00006 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([8552., 8552., 8552., 8552., 8552.], device='cuda:0',\n",
              "        dtype=torch.float16),\n",
              " tensor([1, 0, 2, 4, 3], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_top_results_and_scores(query=query,\n",
        "                             embeddings=embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0ZjVvckzaiF",
        "outputId": "2500223c-9776-4e0f-d3c4-e31a3506cc4e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Time taken to get scores on 87 embeddings: 0.00014 seconds.\n",
            "Query: What is RAT?\n",
            "\n",
            "Results:\n",
            "Score: 8552.0000\n",
            "Our intuition is that the hallucination ∗Corresponding Author.38th Conference on\n",
            "Neural Information Processing Systems (NeurIPS 2024).\n",
            "Page number: 0\n",
            "\n",
            "\n",
            "Score: 8552.0000\n",
            "RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning and\n",
            "Verification in Long-Horizon Generation Zihao Wang Peking University\n",
            "zhwang@stu.pku.edu.cn Anji Liu University of California, Los Angeles\n",
            "liuanji@cs.ucla.edu Haowei Lin Peking University linhaowei@pku.edu.cn Jiaqi Li\n",
            "Beijing Institute of General Artificial Intelligence lijiaqi@bigai.cn Xiaojian\n",
            "Ma Beijing Institute of General Artificial Intelligence xiaojian.ma@ucla.edu\n",
            "Yitao Liang∗ Peking University yitaol@pku.edu.cn Abstract We explore how\n",
            "iterative revising a chain of thoughts with the help of information retrieval\n",
            "significantly improves large language models’ reasoning and generation ability\n",
            "in long-horizon generation tasks, while hugely mitigating hallucination. In\n",
            "particular, the proposed method — retrieval-augmented thoughts (RAT) — revises\n",
            "each thought step one by one with retrieved information relevant to the task\n",
            "query, the current and the past thought steps, after the initial zero-shot CoT\n",
            "is generated. Applying RAT to GPT-3.5, GPT-4, and CodeLLaMA substantially\n",
            "improves their performances on various long-horizon generation tasks; on average\n",
            "of relatively increasing rating scores by 13.63% on code generation, 16.96% on\n",
            "mathematical reasoning, 19.2% on creative writing, and 42.78% on embodied task\n",
            "planning.1 Introduction Large Language Models (LLMs) have achieved fruitful\n",
            "progress on various natural language rea- soning tasks [57, 59, 54, 67, 6],\n",
            "especially when combining large-scale models [49, 41] with sophisticated\n",
            "prompting strategies, notably chain-of-thought (CoT) prompting [57, 27].\n",
            "However, there have been increasing concerns about the factual correctness of\n",
            "LLMs reasoning, citing the possible hallucinations in model responses [43] or\n",
            "the intermediate reasoning paths, i.e. CoTs [13]. This issue becomes more\n",
            "significant when it comes to zero-shot CoT prompting, aka. “let’s think step-\n",
            "by-step” [27] and long-horizon generation tasks that require multi-step and\n",
            "context-aware reasoning, including code generation, task planning, mathematical\n",
            "reasoning, etc. Factually valid intermediate thoughts could be critical to the\n",
            "successful completion of these tasks. Several prompting techniques have been\n",
            "proposed to mitigate this issue, one promising direction, Retrieval Augmented\n",
            "Generation (RAG) [30] seeks insights from human reasoning [22], and utilizes\n",
            "retrieved information to facilitate more factually grounded reasoning. In this\n",
            "paper, we explore how to synergize RAG with sophisticated long-horizon\n",
            "reasoning.\n",
            "Page number: 0\n",
            "\n",
            "\n",
            "Score: 8552.0000\n",
            "Step 0 Draft initial step-by-step zero-shot CoTs based on the task prompt. A\n",
            "task prompt is given by a human user. LLM makes zero-shot step-by-step reasoning\n",
            "based on the prompt. This initial zero-shot CoT answer may be ﬂawed. How to\n",
            "obtain diamond sword in Minecraft?LLM Task Prompt (I) T1: Mine 4 planks (ﬂawed)\n",
            "T2: craft table from planks ... Tn: Craft diamond sword Initial CoTs Retrieve\n",
            "with the task prompt and previous generated CoTs. LLM revises the i-th steps in\n",
            "thought chains (T1:i-1, Ti) based on the retrieved content. The thought chain\n",
            "(T1:i-1, Ti) is replaced with the revised generation T1:i. T1* T2 T3 Tn ... T1*:\n",
            "Mine 4 logs T2: craft table from planks ... Tn: Craft diamond sword Revised CoTs\n",
            "Step 1 - Step n Step 1 Step n Retrieve relevant information and iteratively\n",
            "revise each CoT with all previous generations in context. Retrieval T1 Library\n",
            "R1 Augmented Revision I Rn T1* T1* T2* T3* Tn* ... T1*: Mine 4 logs T2*: craft\n",
            "12 planks ... Tn*: Craft diamond sword Revised CoTs Retrieval Library Rn T1* T2*\n",
            "Tn ... ... Augmented Revision I Rn T1* T2* ... T1 T2 T3 Tn ... * * * Figure 1:\n",
            "Pipeline of Retrieval Augmented Thoughts (RAT). Given a task prompt (denoted as\n",
            "I in the figure), RAT starts from initial step-by-step thoughts (T1, T2, · · · ,\n",
            "Tn) produced by an LLM in zero-shot (“let’s think step by step”).\n",
            "Page number: 1\n",
            "\n",
            "\n",
            "Score: 8552.0000\n",
            "We employ several LLMs of varied scales: GPT-3.5 [6], GPT-4 [41], CodeLLaMA-7b\n",
            "[46]. The results indicate that combing RAT with these LLMs elicits strong\n",
            "advantages over vanilla CoT prompting and RAG approaches. In particular, we\n",
            "observe new state-of-the-art level of performances across our selection of\n",
            "tasks: 1) code generation: HumanEval (+20.94%), HumanEval+ (+18.89%), MBPP\n",
            "(+14.83%), MBPP+ (+1.86%); 2) mathematical reasoning problems: GSM8K (+8.36%),\n",
            "and GSMHard (+31.37%); 3) Minecraft task planning (2.96 times on executability\n",
            "and +51.94% on plausibility); 4) creative writing (+19.19% on human score). Our\n",
            "additional ablation studies further confirm the crucial roles played by the two\n",
            "key ingredients of RAT: revising CoT using RAG and progressive revision &\n",
            "generation. This work reveals how can LLMs revise their reasoning process in a\n",
            "zero-shot fashion with the help of outside knowledge, just as what humans do.2\n",
            "Related Works Retrieval-augmented Generation (RAG). Recently, RAG has gained\n",
            "popularity for boosting the performance of LLMs by guiding their generation\n",
            "process using the retrieved knowledge [65]. Without updating model parameters\n",
            "that may be expensive [29] or unstable [26, 25], RAG is a 2\n",
            "Page number: 1\n",
            "\n",
            "\n",
            "Score: 8552.0000\n",
            "Some thought steps (such as T1 in the figure) may be flawed due to\n",
            "hallucination. RAT iteratively revises each thought step (T ⋆ 1 , T ⋆ 2 , · · ·\n",
            ", T ⋆ i−1, Ti) using RAG from an external knowledge base (denoted as Library).\n",
            "Detailed prompting strategy can be found in Section 3.2.within the intermediate\n",
            "reasoning process could be alleviated through the help of outside knowledge. The\n",
            "resulting prompting strategy, retrieval-augmented thoughts (RAT), is illustrated\n",
            "in Figure 1. Our strategy comprises two key ideas. Firstly, the initial zero-\n",
            "shot CoT produced by LLMs along with the original task prompt will be used as\n",
            "queries to retrieve the information that could help revise the possibly flawed\n",
            "CoT. Secondly, instead of retrieving and revising with the full CoT and\n",
            "producing the final response at once, we devise a progressive approach, where\n",
            "LLMs produce the response step-by-step following the CoT (a series of subtasks),\n",
            "and only the current thought step will be revised based on the information\n",
            "retrieved with task prompt, the current and the past CoTs. This strategy can be\n",
            "an analogy to the human reasoning process: we utilize outside knowledge to\n",
            "adjust our step-by-step thinking during complex long-horizon problem-solving\n",
            "[22]. A comparison of RAT and counterparts can be found in Figure 2. We evaluate\n",
            "RAT on a wide collection of challenging long-horizon tasks, including code\n",
            "generation, mathematical reasoning, embodied task planning, and creative\n",
            "writing.\n",
            "Page number: 1\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils import is_flash_attn_2_available\n"
      ],
      "metadata": {
        "id": "Ub_3onw-zga1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_num_params(model: torch.nn.Module):\n",
        "    return sum([param.numel() for param in model.parameters()])\n",
        "\n",
        "get_model_num_params(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP9O32Ww2cCm",
        "outputId": "edc08c5c-7945-426c-fa58-1f0027220e01"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1777088000"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_mem_size(model: torch.nn.Module):\n",
        "    # Get model parameters and buffer sizes\n",
        "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
        "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
        "\n",
        "    # Calculate various model sizes\n",
        "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
        "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
        "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
        "\n",
        "    return {\"model_mem_bytes\": model_mem_bytes,\n",
        "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
        "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
        "\n",
        "get_model_mem_size(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot-y8PUb2hDV",
        "outputId": "5b4797b4-6130-4823-ef32-51a01a44ce1b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_mem_bytes': 3554176256, 'model_mem_mb': 3389.53, 'model_mem_gb': 3.31}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = '''\n",
        "This is the portion of context of Draft Deed and Presented Deed and there are some discrepancies in it. Please check line by line. You need to find out the minor changes in it.\n",
        "\n",
        "***Draft Deed: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata- 700019,\n",
        "at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded as follows: On the\n",
        "North : By Municipal Premises No 52/5 Ballygunge Circular Road.***\n",
        "\n",
        "***Presented Deed: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata700019, at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded as follows: On\n",
        "the North : By Municipal Premises No Nizam Palace Road.***\n",
        "\n",
        "Find out what is the dicrepancies between them?'''\n",
        "print(f\"Input text:\\n{input_text}\")\n",
        "\n",
        "# Create prompt template for instruction-tuned model\n",
        "dialogue_template = [\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": input_text}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                       tokenize=False, # keep as raw text (not tokenized)\n",
        "                                       add_generation_prompt=True)\n",
        "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cjjlbrb4Ao2",
        "outputId": "dc5e83d5-b4ec-47cd-bfef-21c58058b501"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text:\n",
            "\n",
            "This is the portion of context of Draft Deed and Presented Deed and there are some discrepancies in it. Please check line by line. You need to find out the minor changes in it.\n",
            "\n",
            "***Draft Deed: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata- 700019,\n",
            "at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded as follows: On the\n",
            "North : By Municipal Premises No 52/5 Ballygunge Circular Road.***\n",
            "\n",
            "***Presented Deed: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata700019, at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded as follows: On\n",
            "the North : By Municipal Premises No Nizam Palace Road.***\n",
            "\n",
            "Find out what is the dicrepancies between them?\n",
            "\n",
            "Prompt (formatted):\n",
            "<｜begin▁of▁sentence｜><｜User｜>\n",
            "This is the portion of context of Draft Deed and Presented Deed and there are some discrepancies in it. Please check line by line. You need to find out the minor changes in it.\n",
            "\n",
            "***Draft Deed: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata- 700019,\n",
            "at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded as follows: On the\n",
            "North : By Municipal Premises No 52/5 Ballygunge Circular Road.***\n",
            "\n",
            "***Presented Deed: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata700019, at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded as follows: On\n",
            "the North : By Municipal Premises No Nizam Palace Road.***\n",
            "\n",
            "Find out what is the dicrepancies between them?<｜Assistant｜><think>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
        "\n",
        "# Generate outputs passed on the tokenized input\n",
        "outputs = model.generate(**input_ids,\n",
        "                             max_new_tokens=1024) # define the maximum number of new tokens to create\n",
        "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMLMqu2x4JDO",
        "outputId": "c8f14bc6-452c-4669-8540-7f0ba938c628"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input (tokenized):\n",
            "{'input_ids': tensor([[151646, 151646, 151644,    198,   1986,    374,    279,  13348,    315,\n",
            "           2266,    315,  28564,   1581,    291,    323,  87021,   1581,    291,\n",
            "            323,   1052,    525,   1045,  90267,    304,    432,     13,   5209,\n",
            "           1779,   1555,    553,   1555,     13,   1446,   1184,    311,   1477,\n",
            "            700,    279,   8922,   4344,    304,    432,    382,  12210,  50086,\n",
            "           1581,    291,     25,    220,     19,     17,    323,    220,     19,\n",
            "             17,     32,     11,   3719,   9420,    344,   1816,    328,      3,\n",
            "          14489,    220,     21,     11,  10082,  16629,    425,    745,  13259,\n",
            "            709,     11,  81534,     12,    220,     22,     15,     15,     15,\n",
            "             16,     24,    345,    266,  72834,   4360,     33,   5158,    276,\n",
            "            573,    460,     11,  10942,   4882,    220,     17,     19,    393,\n",
            "            858,  25908,    437,   1988,   6565,    323,    425,  13082,    438,\n",
            "          11017,     25,   1913,    279,    198,  25221,    549,   3216,  44240,\n",
            "          11767,   4909,   2308,    220,     20,     17,     14,     20,    425,\n",
            "            745,  13259,    709,  45761,   9536,     13,  45806,  12210,  21195,\n",
            "            291,   1581,    291,     25,    220,     19,     17,    323,    220,\n",
            "             19,     17,     32,     11,   3719,   9420,    344,   1816,    328,\n",
            "              3,  14489,    220,     21,     11,  10082,  16629,    425,    745,\n",
            "          13259,    709,     11,  81534,     22,     15,     15,     15,     16,\n",
            "             24,     11,    518,  72834,   4360,     33,   5158,    276,    573,\n",
            "            460,     11,  10942,   4882,    220,     17,     19,    393,    858,\n",
            "          25908,    437,   1988,   6565,    323,    425,  13082,    438,  11017,\n",
            "             25,   1913,    198,   1782,   4787,    549,   3216,  44240,  11767,\n",
            "           4909,   2308,    451,    449,    309,  30296,   9536,     13,  45806,\n",
            "           9885,    700,   1128,    374,    279,  21249,    265,    848,  69007,\n",
            "           1948,   1105,     30, 151645, 151648,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "\n",
            "Model output (tokens):\n",
            "tensor([151646, 151646, 151644,    198,   1986,    374,    279,  13348,    315,\n",
            "          2266,    315,  28564,   1581,    291,    323,  87021,   1581,    291,\n",
            "           323,   1052,    525,   1045,  90267,    304,    432,     13,   5209,\n",
            "          1779,   1555,    553,   1555,     13,   1446,   1184,    311,   1477,\n",
            "           700,    279,   8922,   4344,    304,    432,    382,  12210,  50086,\n",
            "          1581,    291,     25,    220,     19,     17,    323,    220,     19,\n",
            "            17,     32,     11,   3719,   9420,    344,   1816,    328,      3,\n",
            "         14489,    220,     21,     11,  10082,  16629,    425,    745,  13259,\n",
            "           709,     11,  81534,     12,    220,     22,     15,     15,     15,\n",
            "            16,     24,    345,    266,  72834,   4360,     33,   5158,    276,\n",
            "           573,    460,     11,  10942,   4882,    220,     17,     19,    393,\n",
            "           858,  25908,    437,   1988,   6565,    323,    425,  13082,    438,\n",
            "         11017,     25,   1913,    279,    198,  25221,    549,   3216,  44240,\n",
            "         11767,   4909,   2308,    220,     20,     17,     14,     20,    425,\n",
            "           745,  13259,    709,  45761,   9536,     13,  45806,  12210,  21195,\n",
            "           291,   1581,    291,     25,    220,     19,     17,    323,    220,\n",
            "            19,     17,     32,     11,   3719,   9420,    344,   1816,    328,\n",
            "             3,  14489,    220,     21,     11,  10082,  16629,    425,    745,\n",
            "         13259,    709,     11,  81534,     22,     15,     15,     15,     16,\n",
            "            24,     11,    518,  72834,   4360,     33,   5158,    276,    573,\n",
            "           460,     11,  10942,   4882,    220,     17,     19,    393,    858,\n",
            "         25908,    437,   1988,   6565,    323,    425,  13082,    438,  11017,\n",
            "            25,   1913,    198,   1782,   4787,    549,   3216,  44240,  11767,\n",
            "          4909,   2308,    451,    449,    309,  30296,   9536,     13,  45806,\n",
            "          9885,    700,   1128,    374,    279,  21249,    265,    848,  69007,\n",
            "          1948,   1105,     30, 151645, 151648,    198,  32313,     11,    773,\n",
            "           358,   1184,    311,   7071,    700,    279,  90267,   1948,    279,\n",
            "         28564,   1581,    291,    323,    279,  87021,   1581,    291,     13,\n",
            "          6771,    752,   1349,   1526,   2176,   9293,  15516,    382,   5338,\n",
            "            11,    279,  28564,   1581,    291,    374,     25,    220,     19,\n",
            "            17,    323,    220,     19,     17,     32,     11,   3719,   9420,\n",
            "           344,   1816,    328,      3,  14489,    220,     21,     11,  10082,\n",
            "         16629,    425,    745,  13259,    709,     11,  81534,     12,    220,\n",
            "            22,     15,     15,     15,     16,     24,     11,    518,  72834,\n",
            "          4360,     33,   5158,    276,    573,    460,     11,  10942,   4882,\n",
            "           220,     17,     19,    393,    858,  25908,    437,   1988,   6565,\n",
            "           323,    425,  13082,     13,    576,   3728,   2661,    374,    330,\n",
            "          1925,    279,   4787,    549,   3216,  44240,  11767,   4909,   2308,\n",
            "           220,     20,     17,     14,     20,    425,    745,  13259,    709,\n",
            "         45761,   9536,   2217,    785,  87021,   1581,    291,    374,    279,\n",
            "          1852,   3650,    279,   5636,   1372,    374,   2155,     25,    330,\n",
            "          1925,    279,   4787,    549,   3216,  44240,  11767,   4909,   2308,\n",
            "           451,    449,    309,  30296,   9536,   2217,  80022,     11,    773,\n",
            "          2176,  53711,    614,    279,   1852,   4586,   5944,    714,   1745,\n",
            "           304,    279,   5636,   5109,     13,  28564,   5711,    330,     20,\n",
            "            17,     14,     20,    425,    745,  13259,    709,  45761,   9536,\n",
            "          1335,   1393,    279,  87021,   1581,    291,   5711,    330,     45,\n",
            "           449,    309,  30296,   9536,   1189,    358,   5775,   3170,   1052,\n",
            "           594,    264,  78005,    304,    279,   5636,   5109,     13,  10696,\n",
            "           279,   2856,   9960,   1030,    264,   2155,   5636,    369,   1045,\n",
            "          2874,     11,    323,   1431,    432,    594,   1012,  10449,    448,\n",
            "           264,   2155,    825,    382,     40,   1265,   1779,    421,   1493,\n",
            "          5636,   5109,    525,    279,   1852,    476,   2155,     13,    330,\n",
            "         82440,   9536,      1,    323,    330,     45,    449,    309,  30296,\n",
            "          9536,      1,    525,   5008,   2155,     13,  45761,   9536,    374,\n",
            "           264,   1632,  21309,    584,   5636,     11,   1393,    451,    449,\n",
            "           309,  30296,   9536,   2578,    387,    264,   3151,   5636,    504,\n",
            "           264,   2155,    949,    315,    279,   3283,    476,    264,  13656,\n",
            "          2747,     13,  18765,   1052,    572,    264,  16523,    979,  20045,\n",
            "           279,  87021,   1581,    291,     11,    476,   7196,    279,   1196,\n",
            "         10602,    311,   3042,    264,   2155,   5636,    369,    264,   3151,\n",
            "          2874,    382,  13394,     11,    279,   1008,   5479,    315,    279,\n",
            "         55308,     11,   1075,    279,  59822,    323,   4282,   8056,   3728,\n",
            "            11,    525,    279,   1852,    304,   2176,     13,   2055,    279,\n",
            "          1887,   4265,    374,    279,   5636,   1372,     13,    576,  78005,\n",
            "           374,   4363,    304,    279,   5636,   1372,     11,    892,   2578,\n",
            "          7802,    279,   3728,    594,  13403,    476,  18048,    382,     40,\n",
            "          1265,   1083,   2908,    421,    279,   5636,   5109,    525,    949,\n",
            "           315,    264,   3119,    476,    264,  13734,     11,    323,   3425,\n",
            "           807,   2299,   9966,    311,    387,    279,   1852,    476,   2155,\n",
            "            13,   1416,    279,   1196,    374,  31544,    279,  55308,     11,\n",
            "           807,   2578,    614,  10602,    311,    990,    264,   2155,   5636,\n",
            "            11,   8365,    369,    264,   2155,   7428,    476,    311,   5648,\n",
            "         51033,    448,   6350,  13737,    382,    641,  12126,     11,    279,\n",
            "          1887,  78005,    374,    279,   5636,   1372,     25,    330,     20,\n",
            "            17,     14,     20,    425,    745,  13259,    709,  45761,   9536,\n",
            "             1,   6165,     13,    330,     45,    449,    309,  30296,   9536,\n",
            "          1189,    576,   2732,    315,    279,  55308,   3565,    525,    279,\n",
            "          1852,    624, 151649,    271,    785,  90267,   1948,    279,  28564,\n",
            "          1581,    291,    323,    279,  87021,   1581,    291,  15503,  10246,\n",
            "           304,    279,   5636,   1372,     13,    576,  28564,   1581,    291,\n",
            "         29102,    279,   3728,    438,    330,   1925,    279,   4787,    549,\n",
            "          3216,  44240,  11767,   4909,   2308,    220,     20,     17,     14,\n",
            "            20,    425,    745,  13259,    709,  45761,   9536,   1335,   1393,\n",
            "           279,  87021,   1581,    291,   4344,    279,   5636,   1372,    311,\n",
            "           330,   1925,    279,   4787,    549,   3216,  44240,  11767,   4909,\n",
            "          2308,    451,    449,    309,  30296,   9536,   1189,    576,   2732,\n",
            "           315,    279,  55308,   3565,     11,   1741,    438,  59822,     11,\n",
            "          4282,   8056,   3728,     11,    323,   4586,   5944,     11,    525,\n",
            "         12966,     13,    576,   1887,   4265,    374,    279,  60369,   5636,\n",
            "          5109,     11,    892,   1231,   8708,    264,  12909,   2297,    304,\n",
            "           279,   3728,    476,    264,   3151,   2874,    369,  59823,    279,\n",
            "          5636,     13, 151643], device='cuda:0')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the output tokens to text\n",
        "outputs_decoded = tokenizer.decode(outputs[0])\n",
        "print(f\"Input text: {input_text}\\n\")\n",
        "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTJZXDRI5lrP",
        "outputId": "61d5e762-2d8a-4198-8157-8c13cd37aa1e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: \n",
            "This is the portion of context of Draft Deed and Presented Deed and there are some discrepancies in it. Please check line by line. You need to find out the minor changes in it.\n",
            "\n",
            "***Draft Deed: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata- 700019,\n",
            "at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded as follows: On the\n",
            "North : By Municipal Premises No 52/5 Ballygunge Circular Road.***\n",
            "\n",
            "***Presented Deed: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata700019, at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded as follows: On\n",
            "the North : By Municipal Premises No Nizam Palace Road.***\n",
            "\n",
            "Find out what is the dicrepancies between them?\n",
            "\n",
            "Output text:\n",
            "<｜begin▁of▁sentence｜>Okay, so I need to figure out the discrepancies between the Draft Deed and the Presented Deed. Let me read through both documents carefully.\n",
            "\n",
            "First, the Draft Deed is: 42 and 42A, Sub-Division S$ Division 6, Police Station Ballygunge, Kolkata- 700019, at MouzaBhowanipore, District South 24 Parganasand Butted and Bounded. The location given is \"On the North : By Municipal Premises No 52/5 Ballygunge Circular Road.\"\n",
            "\n",
            "The Presented Deed is the same except the road number is different: \"On the North : By Municipal Premises No Nizam Palace Road.\"\n",
            "\n",
            "Hmm, so both deeds have the same general structure but differ in the road numbers. Draft uses \"52/5 Ballygunge Circular Road,\" while the Presented Deed uses \"Nizam Palace Road.\" I wonder why there's a discrepancy in the road numbers. Maybe the initial draft had a different road for some reason, and now it's been presented with a different one.\n",
            "\n",
            "I should check if these road numbers are the same or different. \"Circular Road\" and \"Nizam Palace Road\" are quite different. Circular Road is a well-known public road, while Nizam Palace Road might be a specific road from a different part of the city or a historical site. Perhaps there was a mistake when preparing the Presented Deed, or maybe the user intended to present a different road for a specific reason.\n",
            "\n",
            "Also, the other parts of the deed, like the subdivision and police station location, are the same in both. So the main issue is the road number. The discrepancy is likely in the road number, which might affect the location's accuracy or availability.\n",
            "\n",
            "I should also consider if the road numbers are part of a plan or a proposal, and whether they're supposed to be the same or different. If the user is presenting the deed, they might have intended to use a different road, perhaps for a different purpose or to avoid conflicting with existing infrastructure.\n",
            "\n",
            "In summary, the main discrepancy is the road number: \"52/5 Ballygunge Circular Road\" vs. \"Nizam Palace Road.\" The rest of the deed details are the same.\n",
            "</think>\n",
            "\n",
            "The discrepancies between the Draft Deed and the Presented Deed primarily lie in the road number. The Draft Deed specifies the location as \"On the North : By Municipal Premises No 52/5 Ballygunge Circular Road,\" while the Presented Deed changes the road number to \"On the North : By Municipal Premises No Nizam Palace Road.\" The rest of the deed details, such as subdivision, police station location, and general structure, are consistent. The main issue is the differing road numbers, which may reflect a planned change in the location or a specific reason for altering the road.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_list = [\n",
        "    \"What is Retrieval Augmented Thoughts (RAT) and how does it work?\",\n",
        "    \"What are the key differences between RAT and traditional Retrieval-Augmented Generation (RAG)?\",\n",
        "    \"How does RAT improve long-horizon reasoning and generation tasks?\",\n",
        "    \"What role does Chain-of-Thought (CoT) prompting play in RAT?\",\n",
        "    \"What are the main advantages of RAT over vanilla CoT and RAG prompting?\",\n",
        "    \"What are the different types of tasks RAT has been evaluated on?\",\n",
        "    \"How does RAT improve code generation tasks, and what benchmarks are used to evaluate its performance?\",\n",
        "    \"What improvements has RAT shown in mathematical reasoning tasks?\",\n",
        "    \"How does RAT perform in embodied task planning, and what metrics are used to assess its effectiveness?\",\n",
        "    \"What impact does RAT have on creative writing tasks?\",\n",
        "    \"What are the limitations of RAT and how do they affect its performance on different models?\",\n",
        "    \"How does RAT address the issue of hallucination in LLM reasoning?\",\n",
        "    \"What is the iterative refinement process in RAT, and how does it contribute to its effectiveness?\",\n",
        "    \"How do retrieval strategies in RAT influence its performance compared to baseline methods?\",\n",
        "    \"What are the experimental setups used to evaluate RAT across different domains?\",\n",
        "    \"What baseline methods are compared against RAT in the experiments?\",\n",
        "    \"How does RAT utilize external knowledge sources to enhance reasoning?\",\n",
        "    \"What results have been observed when applying RAT to different language models like GPT-3.5 and GPT-4?\",\n",
        "    \"What are the ablation studies conducted on RAT, and what insights do they provide?\",\n",
        "    \"How does RAT ensure causal reasoning during its iterative refinement process?\",\n",
        "    \"What retrieval mechanisms does RAT use to obtain relevant information for each reasoning step?\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "_xtdoTOiGvra"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_formatter(query: str,\n",
        "                     context_items: list[dict]) -> str:\n",
        "    \"\"\"\n",
        "    Augments query with text-based context from context_items.\n",
        "    \"\"\"\n",
        "    # Join context items into one dotted paragraph\n",
        "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
        "\n",
        "    # Create a base prompt with examples to help the model\n",
        "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
        "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
        "Don't return the thinking, only return the answer.\n",
        "Make sure your answers are as explanatory as possible.\n",
        "\n",
        "\\nNow use the following context items to answer the user query:\n",
        "{context}\n",
        "\\nRelevant passages: <extract relevant passages from the context here>\n",
        "User query: {query}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Update base prompt with context items and query\n",
        "    base_prompt = base_prompt.format(context=context, query=query)\n",
        "\n",
        "    # Create prompt template for instruction-tuned model\n",
        "    dialogue_template = [\n",
        "        {\"role\": \"user\",\n",
        "        \"content\": base_prompt}\n",
        "    ]\n",
        "\n",
        "    # Apply the chat template\n",
        "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                          tokenize=False,\n",
        "                                          add_generation_prompt=True)\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "-dwDedq55mD2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "query = random.choice(query_list)\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Get relevant resources\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "\n",
        "# Create a list of context items\n",
        "context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "# Format prompt with context items\n",
        "prompt = prompt_formatter(query=query,\n",
        "                          context_items=context_items)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YehJ2lUEDXWU",
        "outputId": "a54538d9-4e62-4617-cdd6-8b94ccf141aa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the limitations of RAT and how do they affect its performance on different models?\n",
            "[INFO] Time taken to get scores on 87 embeddings: 0.00010 seconds.\n",
            "<｜begin▁of▁sentence｜><｜User｜>Based on the following context items, please answer the query.\n",
            "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
            "Don't return the thinking, only return the answer.\n",
            "Make sure your answers are as explanatory as possible.\n",
            "\n",
            "\n",
            "Now use the following context items to answer the user query:\n",
            "- For embodied 2We used bigcode-evaluation as the tool library for code evaluation. The pass@1 result of DIRECT in the table is slightly different from the result in the bigcode leaderboard, because we tested our pass@1 five times in our original setup and calculated the average value. We used the same settings as DIRECT in all experiments and reported on the relative improvement of RAT compared to baselines to promise fair evaluation and comparison.6\n",
            "- In contrast, RAT can automatically access relevant information from external sources to validate and revise the content of model outputs through a retrieval process. This allows RAT to autonomously verify each step without requiring human labels [34], which explains its significant success in mathematical reasoning.4 Experiments We test our proposed method RAT on a diverse set of benchmarks that highlight long-horizon generation and reasoning. Existing methods traditionally struggle in those benchmarks; “hallucinated\" 5\n",
            "- In The Eleventh International Conference on Learning Representations, ICLR 2023, 2023. [68] S. Zhou, U. Alon, F. F. Xu, Z. Jiang, and G. Neubig. Docprompting: Generating code by retrieving the docs. In The Eleventh International Conference on Learning Representations, 2022.13\n",
            "- 23], our evaluation of open-ended, long-horizon planning in Minecraft focuses on both executability and plausibility. Executability primarily examines whether a plan can be carried out, including the accuracy of each step’s precondi- tions and effects. The executability is automatically calculated using MC-TextWorld [35]. However, 5https://minecraft.wiki/ 6https://www.digminecraft.com/ 15\n",
            "- Specifically, we employed the codeparrot/github-jupyter dataset as our primary search vector library. This dataset is a comprehensive compilation of 452k markdown and code pairs, meticulously extracted from Jupyter notebooks hosted on GitHub BigQuery, representing a rich repository of programming knowledge and examples. We utilized OpenAI’s text-embedding-ada-002 API service for all embedding calculations across different methods and base models.14\n",
            "\n",
            "Relevant passages: <extract relevant passages from the context here>\n",
            "User query: What are the limitations of RAT and how do they affect its performance on different models?\n",
            "Answer:<｜Assistant｜><think>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate an output of tokens\n",
        "outputs = model.generate(**input_ids,\n",
        "                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
        "                             do_sample=True,\n",
        "                             max_new_tokens=1024) # how many new tokens to generate from prompt\n",
        "\n",
        "# Turn the output tokens into text\n",
        "output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWoL6yiUFQMr",
        "outputId": "161087ee-20b0-4bec-b052-5fa87caeec70"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the limitations of RAT and how do they affect its performance on different models?\n",
            "RAG answer:\n",
            "<｜begin▁of▁sentence｜>Alright, the user is asking about the limitations of RAT and how they affect its performance on different models. Let me look through the context to find relevant passages. \n",
            "\n",
            "First, the context mentions that RAT can automatically access external sources to validate and revise model outputs. However, there's a limitation here—it says RAT doesn't require human labels, which is good because it automates the validation. But I also see that there are experiments on long-horizon generation and reasoning where existing methods struggle. RAT shows significant success there. So RAT's ability to automatically validate without human labels is a limitation but also an advantage.\n",
            "\n",
            "Another point is about the evaluation method. The context talks about evaluating open-ended planning in Minecraft, which focuses on both executability and plausibility. RAT uses MC-TextWorld to calculate executability, but it mentions that executing each step requires checking the preconditions and effects. If a step isn't executable, it can't proceed, which could be a limitation if the model's planning isn't always feasible. \n",
            "\n",
            "Also, the reference to the ICLR 2023 paper is about docprompting, which is about generating code by retrieving documents. However, the user might be referring to a different context, so I need to make sure I'm not mixing up anything. The context provided doesn't mention docprompting limitations, so I'll stick to what's given.\n",
            "\n",
            "Putting it together, RAT's limitations are mainly its inability to fully validate without human labels, which is a significant drawback, especially in scenarios where the model's output needs to be cross-checked. Additionally, if the model's planning steps are not executable, RAT might not be the best choice. These limitations can affect performance on certain tasks, particularly when manual validation is required.\n",
            "</think>\n",
            "\n",
            "RAT's limitations include its inability to fully validate model outputs without requiring human labels, which is a significant drawback. Additionally, RAT may not be the best choice for tasks requiring manual validation, especially in scenarios where the model's output steps are not executable.<｜end▁of▁sentence｜>\n",
            "CPU times: user 14.3 s, sys: 22.2 ms, total: 14.4 s\n",
            "Wall time: 14.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(query,\n",
        "        temperature=0.7,\n",
        "        max_new_tokens=1024,\n",
        "        format_answer_text=True,\n",
        "        return_answer_only=True):\n",
        "    \"\"\"\n",
        "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get just the scores and indices of top related results\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings)\n",
        "\n",
        "    # Create a list of context items\n",
        "    context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "    # Add score to context item\n",
        "    for i, item in enumerate(context_items):\n",
        "        item[\"score\"] = scores[i].cpu() # return score back to CPU\n",
        "\n",
        "    # Format the prompt with context items\n",
        "    prompt = prompt_formatter(query=query,\n",
        "                              context_items=context_items)\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate an output of tokens\n",
        "    outputs = model.generate(**input_ids,\n",
        "                                 temperature=temperature,\n",
        "                                 do_sample=True,\n",
        "                                 max_new_tokens=max_new_tokens)\n",
        "\n",
        "    # Turn the output tokens into text\n",
        "    output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "    if format_answer_text:\n",
        "        # Replace special tokens and unnecessary help message\n",
        "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
        "\n",
        "    # Only return the answer without the context items\n",
        "    if return_answer_only:\n",
        "        return output_text\n",
        "\n",
        "    return output_text, context_items"
      ],
      "metadata": {
        "id": "Q2LQ_b5bFV8O"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = random.choice(query_list)\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Answer query with context and return context\n",
        "answer, context_items = ask(query=query,\n",
        "                            temperature=0.7,\n",
        "                            max_new_tokens=512,\n",
        "                            return_answer_only=False)\n",
        "\n",
        "print(f\"Answer:\\n\")\n",
        "print_wrapped(answer)\n",
        "print(f\"Context items:\")\n",
        "context_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1VcvITEFwpG",
        "outputId": "1e9341b2-bebd-4a85-f36c-b1fe238d129a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How does RAT perform in embodied task planning, and what metrics are used to assess its effectiveness?\n",
            "[INFO] Time taken to get scores on 87 embeddings: 0.00010 seconds.\n",
            "Answer:\n",
            "\n",
            "<｜begin▁of▁sentence｜>Okay, let me try to figure out how RAT performs in embodied\n",
            "task planning based on the provided context.   First, I remember that RAT is a\n",
            "system designed for validating and enhancing model outputs through a retrieval\n",
            "process. The context mentions that RAT can automatically access external sources\n",
            "to validate and revise model outputs, which helps it verify each step without\n",
            "human labels. This is a big plus because it means RAT can work on its own\n",
            "without needing human intervention, which is useful for tasks where human labels\n",
            "might be scarce or difficult to obtain.  Looking at the context, there's a\n",
            "mention of experiments comparing RAT to existing methods. The user mentioned\n",
            "that existing methods struggle with long-horizon planning in Minecraft. So, this\n",
            "suggests that RAT is particularly good at handling tasks that require long-term\n",
            "planning, which is a good sign.  The context also talks about the evaluation of\n",
            "open-ended, long-horizon planning in Minecraft, which focuses on both\n",
            "executability and plausibility. Executability involves checking if a plan can be\n",
            "carried out, including the accuracy of each step's preconditions and effects.\n",
            "The system uses MC-TextWorld for this, which is a method for evaluating plans.\n",
            "This tells me that RAT's approach to validation is both comprehensive and\n",
            "methodical.  Additionally, the context mentions that RAT is used in a diverse\n",
            "set of benchmarks for long-horizon generation and reasoning, which further\n",
            "supports its effectiveness in such tasks. The retrieval process through external\n",
            "sources allows RAT to verify each step independently, which is a key feature for\n",
            "tasks requiring high accuracy and reliability.  So, putting this all together,\n",
            "RAT performs well in embodied task planning by relying on external retrieval for\n",
            "validation, ensuring accuracy and reliability. The metrics mentioned, like\n",
            "executability and plausibility, highlight its effectiveness in ensuring that the\n",
            "plans it validates are both feasible and logical. </think>  RAT performs well in\n",
            "embodied task planning by leveraging external retrieval processes for\n",
            "validation, ensuring accuracy and reliability. The system uses metrics like\n",
            "executability and plausibility to assess plans, confirming its effectiveness in\n",
            "long-horizon planning tasks.<｜end▁of▁sentence｜>\n",
            "Context items:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': 5,\n",
              "  'sentence_chunk': 'For embodied 2We used bigcode-evaluation as the tool library for code evaluation. The pass@1 result of DIRECT in the table is slightly different from the result in the bigcode leaderboard, because we tested our pass@1 five times in our original setup and calculated the average value. We used the same settings as DIRECT in all experiments and reported on the relative improvement of RAT compared to baselines to promise fair evaluation and comparison.6',\n",
              "  'chunk_char_count': 453,\n",
              "  'chunk_word_count': 73,\n",
              "  'chunk_token_count': 113.25,\n",
              "  'embedding': tensor([[ 1.8252, -2.6387,  1.8193,  ...,  0.1469,  2.3555,  0.9458]],\n",
              "         device='cuda:0', dtype=torch.float16),\n",
              "  'score': tensor(8560., dtype=torch.float16)},\n",
              " {'page_number': 4,\n",
              "  'sentence_chunk': 'In contrast, RAT can automatically access relevant information from external sources to validate and revise the content of model outputs through a retrieval process. This allows RAT to autonomously verify each step without requiring human labels [34], which explains its significant success in mathematical reasoning.4 Experiments We test our proposed method RAT on a diverse set of benchmarks that highlight long-horizon generation and reasoning. Existing methods traditionally struggle in those benchmarks; “hallucinated\" 5',\n",
              "  'chunk_char_count': 525,\n",
              "  'chunk_word_count': 73,\n",
              "  'chunk_token_count': 131.25,\n",
              "  'embedding': tensor([[ 1.8252, -2.6387,  1.8193,  ...,  0.1469,  2.3555,  0.9458]],\n",
              "         device='cuda:0', dtype=torch.float16),\n",
              "  'score': tensor(8560., dtype=torch.float16)},\n",
              " {'page_number': 12,\n",
              "  'sentence_chunk': 'In The Eleventh International Conference on Learning Representations, ICLR 2023, 2023. [68] S. Zhou, U. Alon, F. F. Xu, Z. Jiang, and G. Neubig. Docprompting: Generating code by retrieving the docs. In The Eleventh International Conference on Learning Representations, 2022.13',\n",
              "  'chunk_char_count': 276,\n",
              "  'chunk_word_count': 40,\n",
              "  'chunk_token_count': 69.0,\n",
              "  'embedding': tensor([[ 1.8252, -2.6387,  1.8193,  ...,  0.1469,  2.3555,  0.9458]],\n",
              "         device='cuda:0', dtype=torch.float16),\n",
              "  'score': tensor(8560., dtype=torch.float16)},\n",
              " {'page_number': 14,\n",
              "  'sentence_chunk': '23], our evaluation of open-ended, long-horizon planning in Minecraft focuses on both executability and plausibility. Executability primarily examines whether a plan can be carried out, including the accuracy of each step’s precondi- tions and effects. The executability is automatically calculated using MC-TextWorld [35]. However, 5https://minecraft.wiki/ 6https://www.digminecraft.com/ 15',\n",
              "  'chunk_char_count': 391,\n",
              "  'chunk_word_count': 47,\n",
              "  'chunk_token_count': 97.75,\n",
              "  'embedding': tensor([[ 1.8252, -2.6387,  1.8193,  ...,  0.1469,  2.3555,  0.9458]],\n",
              "         device='cuda:0', dtype=torch.float16),\n",
              "  'score': tensor(8560., dtype=torch.float16)},\n",
              " {'page_number': 13,\n",
              "  'sentence_chunk': 'Specifically, we employed the codeparrot/github-jupyter dataset as our primary search vector library. This dataset is a comprehensive compilation of 452k markdown and code pairs, meticulously extracted from Jupyter notebooks hosted on GitHub BigQuery, representing a rich repository of programming knowledge and examples. We utilized OpenAI’s text-embedding-ada-002 API service for all embedding calculations across different methods and base models.14',\n",
              "  'chunk_char_count': 452,\n",
              "  'chunk_word_count': 58,\n",
              "  'chunk_token_count': 113.0,\n",
              "  'embedding': tensor([[ 1.8252, -2.6387,  1.8193,  ...,  0.1469,  2.3555,  0.9458]],\n",
              "         device='cuda:0', dtype=torch.float16),\n",
              "  'score': tensor(8560., dtype=torch.float16)}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e608f6inHDRE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}